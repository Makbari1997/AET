{
    "dataset": "atis",
    "bert": "bert-base-uncased",
    "vector_dim": 768,
    "latent_dim": 48,
    "seq_length": "max",
    "finetune": true,
    "finetune_epochs": 60,
    "train_epochs": 300,
    "batch_size": 16,
    "vae_learning_rate": 0.001,
    "encoder": [
        384,
        192,
        96
    ],
    "decoder": [
        96,
        192,
        384,
        768
    ],
    "activation": "tanh",
    "use_ensemble": false,
    "use_evt_vae": true,
    "evt_fpr": 0.01,
    "tail_fraction": 0.3,
    "min_tail_size": 50,
    "fixed_threshold": 0.2,
    "_comment_imbalanced_dataset_options": "New options for handling imbalanced datasets",
    
    "use_class_weights": false,
    "class_weight_method": "balanced",
    "use_focal_loss": false,
    "focal_alpha": 1.0,
    "focal_gamma": 2.0,
    "use_balanced_sampling": true,
    "sampling_method": "oversample",
    "use_warmup": true,
    "warmup_steps": null,
    "warmup_initial_lr": 1e-6,
    "warmup_strategy": "linear",
    "use_lr_schedule": true,
    "lr_schedule_type": "exponential",
    "lr_decay_steps": 1000,
    "lr_decay_rate": 0.96,
    "random_state": 42,
    
    "_comment_configuration_explanations": {
        "use_class_weights": "Enable/disable class weights for imbalanced classes",
        "class_weight_method": "Method to compute class weights: 'balanced', 'effective_number', 'inverse_frequency'",
        "use_focal_loss": "Use focal loss instead of categorical crossentropy (automatically handles imbalance)",
        "focal_alpha": "Alpha parameter for focal loss (class balancing factor)",
        "focal_gamma": "Gamma parameter for focal loss (focusing parameter, higher values focus more on hard examples)",
        "use_balanced_sampling": "Enable balanced batch sampling to ensure equal representation",
        "sampling_method": "Balanced sampling strategy: 'oversample', 'undersample', 'median'",
        "use_warmup": "Enable learning rate warmup to prevent initial instability",
        "warmup_steps": "Number of warmup steps (null means auto-calculate as 10% of total steps)",
        "warmup_initial_lr": "Initial learning rate for warmup phase",
        "warmup_strategy": "Warmup strategy: 'linear', 'cosine', 'constant'",
        "use_lr_schedule": "Enable learning rate decay schedule",
        "lr_schedule_type": "Type of LR schedule: 'exponential', 'cosine', 'polynomial'",
        "lr_decay_steps": "Steps for learning rate decay",
        "lr_decay_rate": "Decay rate for learning rate",
        "random_state": "Random seed for reproducibility"
    }
}